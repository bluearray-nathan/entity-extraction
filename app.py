import streamlit as st
import requests
from bs4 import BeautifulSoup
from google.cloud import language_v1
from google.oauth2 import service_account
import google.generativeai as genai
import pandas as pd
import json

# --- 1. CONFIGURATION & AUTH ---

# A. Google Cloud NLP API (Service Account)
if "gcp_service_account" in st.secrets:
    service_account_info = json.loads(st.secrets["gcp_service_account"])
    credentials = service_account.Credentials.from_service_account_info(service_account_info)
    nlp_client = language_v1.LanguageServiceClient(credentials=credentials)
else:
    st.error("GCP Credentials (gcp_service_account) not found in secrets.")
    st.stop()

# B. Google Gemini API (API Key)
if "gemini_api_key" in st.secrets:
    genai.configure(api_key=st.secrets["gemini_api_key"])
else:
    st.error("Gemini API Key (gemini_api_key) not found in secrets.")
    st.stop()

# --- 2. CORE FUNCTIONS ---

def scrape_body_text(url):
    """Scrapes visible text from a URL."""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove scripts, styles, etc.
        for script in soup(["script", "style", "nav", "footer", "header", "aside"]):
            script.extract()
            
        text = soup.get_text(separator=' ')
        # Clean up whitespace
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        clean_text = ' '.join(chunk for chunk in chunks if chunk)
        
        # Limit text length to avoid hitting NLP API limits/costs if page is huge
        return clean_text[:5000] 
    except Exception as e:
        return None

def analyze_entities(text):
    """Sends text to Google NLP API to get entities."""
    try:
        document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)
        response = nlp_client.analyze_entities(request={'document': document})
        
        # Sort entities by salience (importance)
        sorted_entities = sorted(response.entities, key=lambda x: x.salience, reverse=True)
        
        if not sorted_entities:
            return None, []
        
        # Main entity is the one with highest salience
        main_entity = {
            "name": sorted_entities[0].name,
            "score": sorted_entities[0].salience
        }
        
        # Get top 5 sub-entities
        sub_entities = [e.name for e in sorted_entities[1:6]]
        
        return main_entity, sub_entities
    except Exception as e:
        st.error(f"NLP API Error: {e}")
        return None, []

def llm_audit_gemini(url, main_entity_data, sub_entities):
    """Asks Gemini to audit the entity alignment."""
    
    # We use Gemini 1.5 Flash for speed and efficiency
    model = genai.GenerativeModel('gemini-1.5-flash', generation_config={"response_mime_type": "application/json"})
    
    prompt = f"""
    You are a technical SEO Auditor.
    
    I have a URL: {url}
    
    I ran Google NLP Entity Analysis on the body copy of this page.
    1. The Main Entity identified is: "{main_entity_data['name']}" (Salience Score: {main_entity_data['score']:.2f})
       *Note: A score closer to 1.0 means highly focused. A score below 0.10 often implies dilution.*
    2. The Sub-Entities are: {", ".join(sub_entities)}
    
    Your Task:
    Analyze if the content is focused on the correct topic based on the URL slug and the entities found.
    
    Return ONLY a JSON object with this exact structure:
    {{
        "verdict": "Pass" or "Review Needed",
        "reasoning": "A short, sharp explanation of why.",
        "recommendation": "One specific actionable recommendation."
    }}
    """
    
    try:
        response = model.generate_content(prompt)
        return json.loads(response.text)
    except Exception as e:
        return {"verdict": "Error", "reasoning": str(e), "recommendation": "Check API"}

# --- 3. STREAMLIT UI ---
st.set_page_config(page_title="Entity Auditor", layout="wide")

st.title("üîπ Google NLP + Gemini Entity Auditor")
st.markdown("""
This tool scrapes a URL, runs it through **Google Cloud Natural Language API** to find the main entities, 
and then uses **Google Gemini** to determine if the page content is focused or diluted.
""")

with st.expander("‚ÑπÔ∏è How to interpret results"):
    st.info("""
    - **Salience Score:** 0.0 to 1.0. Higher is better. < 0.10 usually means the page has no clear focus.
    - **Verdict:** Generated by Gemini based on the relationship between the URL and the extracted entities.
    """)

urls_input = st.text_area("Enter URLs (one per line):", height=150, placeholder="https://example.com/topic-a\nhttps://example.com/topic-b")

if st.button("Run Audit", type="primary"):
    if not urls_input:
        st.warning("Please enter at least one URL.")
    else:
        urls = urls_input.strip().split('\n')
        results = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, url in enumerate(urls):
            url = url.strip()
            if not url: continue
            
            status_text.text(f"Processing: {url}")
            
            # 1. Scrape
            text = scrape_body_text(url)
            if not text:
                results.append({"URL": url, "Status": "Scrape Error", "Verdict": "Fail", "Reasoning": "-", "Action": "-"})
                continue
            
            # 2. NLP API
            main_entity, sub_entities = analyze_entities(text)
            if not main_entity:
                results.append({"URL": url, "Status": "No Entities", "Verdict": "Fail", "Reasoning": "-", "Action": "-"})
                continue
            
            # 3. Gemini Audit
            audit = llm_audit_gemini(url, main_entity, sub_entities)
            
            results.append({
                "URL": url,
                "Main Entity": f"{main_entity['name']}",
                "Salience": f"{main_entity['score']:.2f}",
                "Sub Entities": ", ".join(sub_entities),
                "Verdict": audit.get("verdict"),
                "Reasoning": audit.get("reasoning"),
                "Action": audit.get("recommendation")
            })
            
            progress_bar.progress((i + 1) / len(urls))
            
        status_text.text("Audit Complete!")
        
        # Display Results
        df = pd.DataFrame(results)
        
        # Stylize the dataframe to highlight "Review Needed"
        def highlight_verdict(val):
            color = 'red' if val == "Review Needed" else 'green'
            return f'color: {color}; font-weight: bold'

        st.dataframe(df.style.map(highlight_verdict, subset=['Verdict']), use_container_width=True)





